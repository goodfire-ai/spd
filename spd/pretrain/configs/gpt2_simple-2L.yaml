wandb_project: spd
dtype: float32
batch_size: 8
num_iterations: 100_000
warmup_iters: 600
learning_rate: 3e-4
learning_rate_decay_frac: 0.1
weight_decay: 0.1
grad_clip: 1.0
val_loss_every: 100
val_max_steps: 20
sample_every: 1000
intermediate_checkpoints: false

model:
  model_type: GPT2Simple
  block_size: 512
  vocab_size: 4019
  n_layer: 2
  n_head: 4
  n_embd: 128
  flash_attention: false

train_dataset_config:
  name: SimpleStories/SimpleStories
  is_tokenized: false
  hf_tokenizer_path: SimpleStories/test-SimpleStories-gpt2-1.25M
  split: train
  streaming: false
  n_ctx: 513  # model block_size + 1 for next-token label indexing
  seed: 0
  column_name: story

val_dataset_config:
  name: SimpleStories/SimpleStories
  is_tokenized: false
  hf_tokenizer_path: SimpleStories/test-SimpleStories-gpt2-1.25M
  split: test
  streaming: false
  n_ctx: 513  # model block_size + 1 for next-token label indexing
  seed: 0
  column_name: story
