# Mem experiment config for SPD decomposition
# --- WandB ---
wandb_project: spd
wandb_run_name: null
wandb_run_name_prefix: ""

# --- General ---
seed: 0
C: 1000
n_mask_samples: 1
ci_fn_type: "shared_mlp"
ci_fn_hidden_dims: [200]
sigmoid_type: "leaky_hard"
target_module_patterns:
  - "block.attn.q_proj"
  - "block.attn.k_proj"
  - "block.attn.v_proj"
  - "block.attn.o_proj"
  - "block.mlp.gate_proj"
  - "block.mlp.up_proj"
  - "block.mlp.down_proj"
  - "unembed"
identity_module_patterns: null
use_delta_component: true

# --- Loss config ---
loss_metric_configs:
- coeff: 5e-2
  classname: ImportanceMinimalityLoss
  pnorm: 2.0
  p_anneal_start_frac: 0.0
  p_anneal_final_p: 0.5
  p_anneal_end_frac: 1.0
  eps: 1.0e-12
- coeff: 1.0
  classname: StochasticReconSubsetLoss
- coeff: 0.5
  init: random
  step_size: 1.0
  n_steps: 1
  mask_scope: shared_across_batch
  classname: PGDReconSubsetLoss
- coeff: 10.0
  classname: FaithfulnessLoss
output_loss_type: mem  # Only compute KL at final sequence position

# --- Training ---
batch_size: 500
eval_batch_size: 500
steps: 20_000
lr: 1e-3
lr_schedule: constant
lr_warmup_pct: 0.0

# --- Faithfulness Warmup ---
faithfulness_warmup_steps: 100
faithfulness_warmup_lr: 0.01
faithfulness_warmup_weight_decay: 0.1

# --- Logging & Saving ---
train_log_freq: 100
eval_freq: 500
n_eval_steps: 50
slow_eval_freq: 2_500
slow_eval_on_first_step: true
save_freq: null
ci_alive_threshold: 0.01
n_examples_until_dead: 1000
eval_metric_configs:
  - classname: "CIHistograms"
    n_batches_accum: 5
  - classname: "ComponentActivationDensity"
  - classname: "CI_L0"
    groups: null
  - classname: "CIMeanPerComponent"
  # NOTE: CEandKLLosses is NOT compatible with the mem task because it computes
  # next-token prediction CE, but mem uses a separate label token at the final position.
  # - classname: "CEandKLLosses"  
  #   rounding_threshold: 0.0

# --- Pretrained model info ---
pretrained_model_class: "spd.experiments.mem.models.MemTransformer"
pretrained_model_path: "wandb:goodfire/spd/runs/vkl7m64f"  # Set this to the path of a trained mem model

# --- Task Specific ---
task_config:
  task_name: mem

