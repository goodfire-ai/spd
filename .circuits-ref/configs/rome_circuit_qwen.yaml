# Attribution Graph Pipeline - Knowledge Circuit Analysis (Qwen3-4B)
# Based on rome_circuit.yaml, adapted for Qwen/Qwen3-4B-Instruct-2507

config:
  # Model settings
  model_name: "Qwen/Qwen3-4B-Instruct-2507"
  device: "cuda"
  dtype: "bfloat16"

  # Graph generation
  k: 5                    # Number of top logits to trace
  tau: 0.005              # Node influence threshold

  # Template
  use_chat_template: true
  answer_prefix: ""       # Default prefix (can override per-sequence)

  # Labeling
  label_neurons: true     # Fetch neuron descriptions from database

  # Clustering
  skip_special_tokens: true
  min_cluster_size: 5
  max_cluster_depth: 1

  # LLM Analysis
  run_llm_analysis: true
  llm_model: "gpt-5.2"
  llm_provider: "openai"
  parallel_llm: true

  # Functional splitting
  functional_split: true
  functional_split_min_size: 2
  use_prompt_answer_split: true
  use_position_split: true
  max_position_gap: 3
  use_layer_split: false
  use_semantic_split: false
  use_llm_split: true

  # Output
  output_dir: "outputs/rome_circuit_qwen/"
  save_intermediate: true

sequences:

  # Causal/relational
  - prompt: "The fall of the Roman Empire was accelerated by invasions from"
    answer_prefix: " Answer:"
